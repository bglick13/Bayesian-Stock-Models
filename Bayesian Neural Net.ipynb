{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import theano\n",
    "floatX = theano.config.floatX\n",
    "import pymc3 as pm\n",
    "import theano.tensor as T\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "sns.set_style('white')\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    combined = pd.read_pickle('combined.pkl')\n",
    "except:\n",
    "    prices, combined = build_prices_dfs()\n",
    "    pd.to_pickle(combined, 'combined.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURE_COLS = ['beta_abs', 'momentum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = combined[FEATURE_COLS]\n",
    "y = np.where(combined['ra_month_return'] > 0, 1, 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_nn(ann_input, ann_output, n_hidden=64):\n",
    "    # Initialize random weights between each layer\n",
    "    init_1 = np.random.randn(X.shape[1], n_hidden).astype(floatX)\n",
    "    init_2 = np.random.randn(n_hidden, n_hidden).astype(floatX)\n",
    "    init_out = np.random.randn(n_hidden).astype(floatX)\n",
    "\n",
    "    with pm.Model() as neural_network:\n",
    "        # Weights from input to hidden layer\n",
    "        weights_in_1 = pm.Normal('w_in_1', 0, sd=1,\n",
    "                                 shape=(X.shape[1], n_hidden),\n",
    "                                 testval=init_1)\n",
    "\n",
    "        # Weights from 1st to 2nd layer\n",
    "        weights_1_2 = pm.Normal('w_1_2', 0, sd=1,\n",
    "                                shape=(n_hidden, n_hidden),\n",
    "                                testval=init_2)\n",
    "\n",
    "        # Weights from hidden layer to output\n",
    "        weights_2_out = pm.Normal('w_2_out', 0, sd=1,\n",
    "                                  shape=(n_hidden,),\n",
    "                                  testval=init_out)\n",
    "\n",
    "        # Build neural-network using tanh activation function\n",
    "        act_1 = pm.math.tanh(pm.math.dot(ann_input,\n",
    "                                         weights_in_1))\n",
    "        act_2 = pm.math.tanh(pm.math.dot(act_1,\n",
    "                                         weights_1_2))\n",
    "        act_out = pm.math.sigmoid(pm.math.dot(act_2,\n",
    "                                              weights_2_out))\n",
    "\n",
    "        # Binary classification -> Bernoulli likelihood\n",
    "        out = pm.Bernoulli('out',\n",
    "                           act_out,\n",
    "                           observed=ann_output,\n",
    "                           total_size=y_train.shape[0] # IMPORTANT for minibatches\n",
    "                          )\n",
    "    return neural_network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ann_input = theano.shared(X_train.values)\n",
    "ann_output = theano.shared(y_train)\n",
    "neural_network = construct_nn(ann_input, ann_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 3.5455e+05:   1%|          | 169/20000 [01:08<2:11:52,  2.51it/s]"
     ]
    }
   ],
   "source": [
    "with neural_network:\n",
    "    # Run ADVI to estimate posterior means, standard deviations, and the evidence lower bound (ELBO)\n",
    "    # here is a good chance to demonstrate `cost_part_grad_scale` parameter usage\n",
    "    # the reason is described here: approximateinference.org/accepted/RoederEtAl2016.pdf\n",
    "    # to be short it is used to reduce variance of gradient on final iterations\n",
    "    s = theano.shared(pm.floatX(1))\n",
    "    inference = pm.ADVI(cost_part_grad_scale=s)\n",
    "    # ADVI has nearly converged\n",
    "    pm.fit(n=20000, method=inference)\n",
    "    # It is time to set `s` to zero\n",
    "    s.set_value(pm.floatX(0))\n",
    "    approx = pm.fit(n=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:new_theano]",
   "language": "python",
   "name": "conda-env-new_theano-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
